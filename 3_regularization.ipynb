{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save # hint to help gc free up memory\n",
    "    \n",
    "    print(\"Training set\", train_dataset.shape, train_labels.shape)\n",
    "    print(\"Validation set\", valid_dataset.shape, valid_labels.shape)\n",
    "    print(\"Test set\", test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    # One-hot encoding\n",
    "    labels = (np.arange(num_labels) == labels[:, None]).astype(np.float32)\n",
    "    \n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta_vals = np.logspace(-4, -2, 20)\n",
    "accuracy_val = []\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = tf_train_labels, logits = logits)) + beta_regul * tf.nn.l2_loss(weights)\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for training, validation, and test data\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this computation and iterate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 20.279421\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 8.7%\n",
      "Minibatch loss at step 500: 1.716619\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 1000: 1.597043\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 1500: 1.250239\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 2000: 1.024586\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 2500: 1.438433\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 3000: 1.027863\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.1%\n",
      "L2 regularization(beta = 0.00010) test accuracy: 86.6%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 20.222786\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 15.3%\n",
      "Minibatch loss at step 500: 1.946642\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 1000: 1.780367\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 1500: 1.219992\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 2000: 1.087101\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 2500: 1.294847\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 3000: 1.153576\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.7%\n",
      "L2 regularization(beta = 0.00013) test accuracy: 86.8%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 17.234304\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 10.9%\n",
      "Minibatch loss at step 500: 1.461100\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 1000: 1.684747\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 1500: 1.351881\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 2000: 1.247706\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 2500: 1.248263\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 3000: 1.069613\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.7%\n",
      "L2 regularization(beta = 0.00016) test accuracy: 86.6%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 18.801266\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 13.9%\n",
      "Minibatch loss at step 500: 1.766684\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 1000: 1.794193\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1500: 1.281621\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 2000: 1.127529\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 2500: 1.387748\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 3000: 1.078999\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.1%\n",
      "L2 regularization(beta = 0.00021) test accuracy: 87.1%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 16.846653\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 15.6%\n",
      "Minibatch loss at step 500: 1.952752\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 1000: 1.752353\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1500: 1.471080\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 2000: 1.268655\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 2500: 1.277137\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 3000: 1.015691\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.3%\n",
      "L2 regularization(beta = 0.00026) test accuracy: 87.4%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 15.406171\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 13.3%\n",
      "Minibatch loss at step 500: 2.096103\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 1000: 1.774491\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1500: 1.344891\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 2000: 1.028779\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2500: 1.285836\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 3000: 0.978996\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.8%\n",
      "L2 regularization(beta = 0.00034) test accuracy: 87.5%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 16.240414\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 14.9%\n",
      "Minibatch loss at step 500: 2.160010\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 1000: 1.956921\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 1500: 1.399297\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 2000: 1.070641\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2500: 1.313254\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 3000: 0.938924\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.1%\n",
      "L2 regularization(beta = 0.00043) test accuracy: 88.0%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 20.646196\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 10.5%\n",
      "Minibatch loss at step 500: 2.436834\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 1000: 1.948515\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 1500: 1.409483\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2000: 1.074623\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2500: 1.233450\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 3000: 0.970634\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.8%\n",
      "L2 regularization(beta = 0.00055) test accuracy: 88.0%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 22.049580\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 9.8%\n",
      "Minibatch loss at step 500: 2.947742\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 1000: 2.052821\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 1500: 1.363137\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2000: 0.997125\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2500: 1.121218\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 3000: 0.922466\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.0%\n",
      "L2 regularization(beta = 0.00070) test accuracy: 88.7%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 19.599438\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 11.9%\n",
      "Minibatch loss at step 500: 2.446833\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 1000: 1.826283\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 1500: 1.324336\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2000: 0.925590\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2500: 1.095325\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 3000: 0.833200\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.1%\n",
      "L2 regularization(beta = 0.00089) test accuracy: 88.5%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 22.299349\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 9.3%\n",
      "Minibatch loss at step 500: 2.557848\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 1000: 1.734098\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 1500: 1.246957\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2000: 0.862195\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 2500: 1.071074\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 3000: 0.819076\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.5%\n",
      "L2 regularization(beta = 0.00113) test accuracy: 88.7%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 22.241888\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 15.8%\n",
      "Minibatch loss at step 500: 3.019362\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1000: 1.740400\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 1500: 1.121689\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2000: 0.752931\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss at step 2500: 0.969389\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 82.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 3000: 0.765864\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.5%\n",
      "L2 regularization(beta = 0.00144) test accuracy: 88.7%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 21.685200\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 14.2%\n",
      "Minibatch loss at step 500: 2.897407\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 1000: 1.511488\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 1500: 0.960850\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 2000: 0.688438\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 2500: 0.938408\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 3000: 0.757262\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.5%\n",
      "L2 regularization(beta = 0.00183) test accuracy: 88.7%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 23.708254\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 13.5%\n",
      "Minibatch loss at step 500: 2.699578\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 1000: 1.317185\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1500: 0.843527\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 2000: 0.662095\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.7%\n",
      "Minibatch loss at step 2500: 0.926198\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 82.3%\n",
      "Minibatch loss at step 3000: 0.755028\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.4%\n",
      "L2 regularization(beta = 0.00234) test accuracy: 88.6%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 22.749344\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 17.4%\n",
      "Minibatch loss at step 500: 2.541186\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 1000: 1.124404\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1500: 0.789882\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 2000: 0.633885\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.8%\n",
      "Minibatch loss at step 2500: 0.927271\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 3000: 0.760505\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.3%\n",
      "L2 regularization(beta = 0.00298) test accuracy: 88.6%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 27.580708\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 14.4%\n",
      "Minibatch loss at step 500: 2.335557\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 1000: 0.969251\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 1500: 0.760869\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 2000: 0.632131\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 2500: 0.927985\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 3000: 0.766998\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.2%\n",
      "L2 regularization(beta = 0.00379) test accuracy: 88.6%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 33.485996\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 14.8%\n",
      "Minibatch loss at step 500: 1.852517\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 0.870722\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1500: 0.748537\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 2000: 0.633897\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 2500: 0.933818\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 3000: 0.777612\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.1%\n",
      "L2 regularization(beta = 0.00483) test accuracy: 88.5%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 34.245720\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 12.9%\n",
      "Minibatch loss at step 500: 1.488340\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1000: 0.843329\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 1500: 0.749646\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 2000: 0.640101\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 2500: 0.941535\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 3000: 0.790447\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.0%\n",
      "L2 regularization(beta = 0.00616) test accuracy: 88.4%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 41.719650\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 16.5%\n",
      "Minibatch loss at step 500: 1.174775\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 1000: 0.843110\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1500: 0.759042\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2000: 0.650852\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss at step 2500: 0.951163\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 3000: 0.805643\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.9%\n",
      "L2 regularization(beta = 0.00785) test accuracy: 88.3%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 50.021175\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.5%\n",
      "Minibatch loss at step 500: 0.957159\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1000: 0.852639\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1500: 0.771452\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2000: 0.663694\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 82.3%\n",
      "Minibatch loss at step 2500: 0.963018\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 3000: 0.824072\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.8%\n",
      "L2 regularization(beta = 0.01000) test accuracy: 88.1%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "for beta_val in beta_vals:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        print(\"Initialized\")\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to find the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : beta_val}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "            if step % 500 == 0:\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "                \n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        print(\"L2 regularization(beta = %.5f) test accuracy: %.1f%%\\n\\n\" % (beta_val, test_accuracy))\n",
    "        accuracy_val.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best beta=0.001438, accuracy=88.7%\n"
     ]
    }
   ],
   "source": [
    "print(\"Best beta=%f, accuracy=%.1f%%\" % (beta_vals[np.argmax(accuracy_val)], max(accuracy_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(beta_vals, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title(\"Test accuracy by regularization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta_vals = np.logspace(-4, -2, 20)\n",
    "hidden_size = 1024\n",
    "accuracy_val = []\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size), name='train_dataset')\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels), name='train_labels')\n",
    "    tf_valid_dataset = tf.constant(valid_dataset, name='valid_dataset')\n",
    "    tf_test_dataset = tf.constant(test_dataset, name='test_dataset')\n",
    "    beta_regul = tf.placeholder(tf.float32, name='beta')\n",
    "    \n",
    "    # Variables.\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_size]), name='weights1')\n",
    "    biases1 = tf.Variable(tf.zeros([hidden_size]), name='biases1')\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([hidden_size, num_labels]), name='weights2')\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]), name='biases2')\n",
    "    \n",
    "    # Training computation.\n",
    "    hidden = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    logits = tf.matmul(hidden, weights2) + biases2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = tf_train_labels, logits = logits))\n",
    "    loss += beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2))\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for training, validation, and test data\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    valid_hidden = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(valid_hidden, weights2) + biases2)\n",
    "    \n",
    "    test_hidden = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_hidden, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 456.162231\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 27.0%\n",
      "Minibatch loss at step 500: 44.605583\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1000: 35.591049\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1500: 37.732590\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2000: 30.247379\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2500: 26.160698\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 3000: 23.643360\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 82.2%\n",
      "L2 regularization(beta = 0.00010) test accuracy: 88.7%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 386.617706\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 35.3%\n",
      "Minibatch loss at step 500: 55.842670\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1000: 43.136940\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1500: 38.996239\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2000: 34.904472\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 2500: 31.676989\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss at step 3000: 27.226171\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 82.8%\n",
      "L2 regularization(beta = 0.00013) test accuracy: 89.5%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 397.785583\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 35.5%\n",
      "Minibatch loss at step 500: 67.054893\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1000: 53.445656\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1500: 47.600391\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2000: 39.713516\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2500: 34.904987\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 3000: 31.297956\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 82.9%\n",
      "L2 regularization(beta = 0.00016) test accuracy: 89.4%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 459.365997\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 31.2%\n",
      "Minibatch loss at step 500: 80.721664\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1000: 60.810783\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1500: 53.227322\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2000: 45.169163\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2500: 40.720993\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 82.8%\n",
      "Minibatch loss at step 3000: 34.313580\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 83.5%\n",
      "L2 regularization(beta = 0.00021) test accuracy: 90.2%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 472.211365\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 27.6%\n",
      "Minibatch loss at step 500: 86.884735\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1000: 68.029480\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 61.486763\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2000: 49.963497\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 2500: 42.876236\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 3000: 36.961235\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 83.1%\n",
      "L2 regularization(beta = 0.00026) test accuracy: 89.6%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 398.793121\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 26.0%\n",
      "Minibatch loss at step 500: 105.619011\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1000: 81.797951\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 68.014297\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 2000: 55.025288\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 2500: 45.686298\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 3000: 37.206978\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 83.6%\n",
      "L2 regularization(beta = 0.00034) test accuracy: 90.2%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 490.203491\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 26.0%\n",
      "Minibatch loss at step 500: 116.673615\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1000: 93.535484\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 1500: 72.609398\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2000: 56.726967\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 82.9%\n",
      "Minibatch loss at step 2500: 45.632362\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 83.2%\n",
      "Minibatch loss at step 3000: 35.985016\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.6%\n",
      "L2 regularization(beta = 0.00043) test accuracy: 90.9%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 456.418640\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 29.8%\n",
      "Minibatch loss at step 500: 139.733826\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1000: 101.379471\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1500: 77.153419\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2000: 57.042679\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 2500: 42.817558\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss at step 3000: 32.125324\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.8%\n",
      "L2 regularization(beta = 0.00055) test accuracy: 91.4%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 557.367676\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 23.8%\n",
      "Minibatch loss at step 500: 162.079483\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 1000: 108.662331\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 1500: 77.773003\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 2000: 53.095905\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 2500: 37.556427\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 3000: 26.279139\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 86.2%\n",
      "L2 regularization(beta = 0.00070) test accuracy: 92.2%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 638.529785\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 35.0%\n",
      "Minibatch loss at step 500: 184.530975\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1000: 114.934341\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 1500: 73.258293\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 2000: 46.413570\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 84.4%\n",
      "Minibatch loss at step 2500: 29.821404\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 3000: 19.076830\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.6%\n",
      "L2 regularization(beta = 0.00089) test accuracy: 92.6%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 649.385742\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 31.3%\n",
      "Minibatch loss at step 500: 205.520584\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 1000: 113.640701\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 1500: 64.647469\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 2000: 36.236851\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 2500: 20.886192\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 3000: 11.936536\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.2%\n",
      "L2 regularization(beta = 0.00113) test accuracy: 92.8%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 907.051880\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 34.1%\n",
      "Minibatch loss at step 500: 225.303192\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1000: 106.116608\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1500: 51.465446\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 2000: 25.081545\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 2500: 12.565917\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 3000: 6.283693\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.0%\n",
      "L2 regularization(beta = 0.00144) test accuracy: 92.8%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 916.796814\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 28.1%\n",
      "Minibatch loss at step 500: 232.239334\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1000: 90.988335\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 1500: 36.354771\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 2000: 14.815155\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 2500: 6.377484\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 3000: 2.777709\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.1%\n",
      "L2 regularization(beta = 0.00183) test accuracy: 92.5%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1047.975586\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 34.6%\n",
      "Minibatch loss at step 500: 229.574890\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1000: 69.787628\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss at step 1500: 21.955273\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 2000: 7.234285\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 2500: 2.817902\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 3000: 1.169410\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 86.9%\n",
      "L2 regularization(beta = 0.00234) test accuracy: 92.5%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1369.427368\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 34.4%\n",
      "Minibatch loss at step 500: 211.571869\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 1000: 47.093594\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 1500: 11.128830\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 2000: 2.978937\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 2500: 1.314582\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 3000: 0.678812\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.3%\n",
      "L2 regularization(beta = 0.00298) test accuracy: 92.2%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1460.374756\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 35.0%\n",
      "Minibatch loss at step 500: 176.541153\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 82.3%\n",
      "Minibatch loss at step 1000: 26.772266\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 1500: 4.618036\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 2000: 1.204555\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 2500: 0.870783\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 3000: 0.593487\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.9%\n",
      "L2 regularization(beta = 0.00379) test accuracy: 91.8%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1910.107422\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 31.3%\n",
      "Minibatch loss at step 500: 133.866531\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 1000: 12.485276\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 1500: 1.759684\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 2000: 0.740638\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 2500: 0.826674\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 3000: 0.604625\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.3%\n",
      "L2 regularization(beta = 0.00483) test accuracy: 91.1%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2232.828613\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 25.1%\n",
      "Minibatch loss at step 500: 87.525612\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 1000: 4.753775\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 1500: 0.899450\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 2000: 0.676753\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 2500: 0.844185\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 3000: 0.633881\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 84.8%\n",
      "L2 regularization(beta = 0.00616) test accuracy: 90.8%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2889.819824\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 32.3%\n",
      "Minibatch loss at step 500: 48.153076\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 1000: 1.748888\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 1500: 0.760344\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 2000: 0.690775\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 2500: 0.888832\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 84.4%\n",
      "Minibatch loss at step 3000: 0.661084\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 84.3%\n",
      "L2 regularization(beta = 0.00785) test accuracy: 90.6%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 3456.477051\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 28.3%\n",
      "Minibatch loss at step 500: 21.319233\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 1000: 0.984602\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 1500: 0.771507\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 2000: 0.714823\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 2500: 0.919287\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 83.7%\n",
      "Minibatch loss at step 3000: 0.704724\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 83.8%\n",
      "L2 regularization(beta = 0.01000) test accuracy: 90.1%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "for beta_val in beta_vals:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        print(\"Initialized\")\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to find the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : beta_val}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "            if step % 500 == 0:\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "                \n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        print(\"L2 regularization(beta = %.5f) test accuracy: %.1f%%\\n\\n\" % (beta_val, test_accuracy))\n",
    "        accuracy_val.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best beta=0.001438, accuracy=92.8%\n"
     ]
    }
   ],
   "source": [
    "print(\"Best beta=%f, accuracy=%.1f%%\" % (beta_vals[np.argmax(accuracy_val)], max(accuracy_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(beta_vals, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title(\"Test accuracy by regularization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 334.998901\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 39.7%\n",
      "Minibatch loss at step 500: 29.857431\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 1000: 28.401228\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 1500: 27.016052\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 2000: 25.698433\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 2500: 24.445074\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 3000: 23.252844\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.9%\n",
      "L2 regularization(beta = 0.00010) test accuracy: 82.6%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 341.121765\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 22.1%\n",
      "Minibatch loss at step 500: 37.637810\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 1000: 35.314487\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 1500: 33.134583\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 2000: 31.089241\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 2500: 29.170151\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 3000: 27.369524\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "L2 regularization(beta = 0.00013) test accuracy: 81.3%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 383.304718\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 32.0%\n",
      "Minibatch loss at step 500: 47.229191\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 1000: 43.546097\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 1500: 40.150219\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 2000: 37.019169\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 2500: 34.132282\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 3000: 31.470530\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.6%\n",
      "L2 regularization(beta = 0.00016) test accuracy: 82.7%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 479.588684\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 32.2%\n",
      "Minibatch loss at step 500: 58.501396\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.7%\n",
      "Minibatch loss at step 1000: 52.751297\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.7%\n",
      "Minibatch loss at step 1500: 47.566372\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.7%\n",
      "Minibatch loss at step 2000: 42.891075\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.7%\n",
      "Minibatch loss at step 2500: 38.675316\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.7%\n",
      "Minibatch loss at step 3000: 34.873920\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.8%\n",
      "L2 regularization(beta = 0.00021) test accuracy: 81.1%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 526.458557\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 49.2%\n",
      "Minibatch loss at step 500: 72.535736\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 1000: 63.576134\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 1500: 55.723225\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 2000: 48.840298\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.7%\n",
      "Minibatch loss at step 2500: 42.807556\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.7%\n",
      "Minibatch loss at step 3000: 37.519981\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.7%\n",
      "L2 regularization(beta = 0.00026) test accuracy: 82.0%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 480.519165\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 34.5%\n",
      "Minibatch loss at step 500: 89.164665\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 1000: 75.375313\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 1500: 63.718483\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 2000: 53.864391\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 2500: 45.534248\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 3000: 38.492359\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "L2 regularization(beta = 0.00034) test accuracy: 81.7%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 412.116760\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 23.3%\n",
      "Minibatch loss at step 500: 108.449715\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 1000: 87.548866\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 1500: 70.676109\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 2000: 57.055130\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 2500: 46.059246\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 3000: 37.182541\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "L2 regularization(beta = 0.00043) test accuracy: 81.6%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 528.189514\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 32.9%\n",
      "Minibatch loss at step 500: 130.665741\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 1000: 99.466949\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.1%\n",
      "Minibatch loss at step 1500: 75.717438\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.1%\n",
      "Minibatch loss at step 2000: 57.638557\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.0%\n",
      "Minibatch loss at step 2500: 43.876335\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.9%\n",
      "Minibatch loss at step 3000: 33.400082\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "L2 regularization(beta = 0.00055) test accuracy: 80.5%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 679.714417\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 34.9%\n",
      "Minibatch loss at step 500: 154.790573\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.6%\n",
      "Minibatch loss at step 1000: 109.334969\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.6%\n",
      "Minibatch loss at step 1500: 77.227806\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.6%\n",
      "Minibatch loss at step 2000: 54.549221\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 2500: 38.530422\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 3000: 27.215876\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.5%\n",
      "L2 regularization(beta = 0.00070) test accuracy: 80.9%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 637.333008\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 34.0%\n",
      "Minibatch loss at step 500: 178.376205\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 1000: 114.533035\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.2%\n",
      "Minibatch loss at step 1500: 73.540184\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.2%\n",
      "Minibatch loss at step 2000: 47.219269\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.1%\n",
      "Minibatch loss at step 2500: 30.319016\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 3000: 19.467859\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.0%\n",
      "L2 regularization(beta = 0.00089) test accuracy: 82.0%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 707.294800\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 27.3%\n",
      "Minibatch loss at step 500: 201.764114\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.1%\n",
      "Minibatch loss at step 1000: 114.723076\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.0%\n",
      "Minibatch loss at step 1500: 65.231575\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.9%\n",
      "Minibatch loss at step 2000: 37.090843\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 2500: 21.090599\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.9%\n",
      "Minibatch loss at step 3000: 11.994974\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.3%\n",
      "L2 regularization(beta = 0.00113) test accuracy: 81.8%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 885.477722\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 34.8%\n",
      "Minibatch loss at step 500: 220.285202\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 1000: 107.279709\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 1500: 52.245720\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 2000: 25.444748\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 2500: 12.396155\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 3000: 6.051607\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "L2 regularization(beta = 0.00144) test accuracy: 84.5%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 915.040283\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 31.0%\n",
      "Minibatch loss at step 500: 230.348160\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 1000: 92.082222\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.1%\n",
      "Minibatch loss at step 1500: 36.810806\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.1%\n",
      "Minibatch loss at step 2000: 14.721768\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 2500: 5.910168\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 3000: 2.408621\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "L2 regularization(beta = 0.00183) test accuracy: 85.0%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1244.797363\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 34.4%\n",
      "Minibatch loss at step 500: 228.740997\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.0%\n",
      "Minibatch loss at step 1000: 71.097366\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.9%\n",
      "Minibatch loss at step 1500: 22.105322\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 2000: 6.909850\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 2500: 2.218477\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 3000: 0.766730\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "L2 regularization(beta = 0.00234) test accuracy: 85.2%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1282.404907\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 28.8%\n",
      "Minibatch loss at step 500: 211.270264\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.6%\n",
      "Minibatch loss at step 1000: 47.651100\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.9%\n",
      "Minibatch loss at step 1500: 10.785112\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 2000: 2.527565\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 2500: 0.675770\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 3000: 0.254273\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "L2 regularization(beta = 0.00298) test accuracy: 85.1%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1660.362305\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 41.0%\n",
      "Minibatch loss at step 500: 178.400909\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 1000: 26.760002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 1500: 4.128829\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 2000: 0.763635\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 2500: 0.250555\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 3000: 0.167075\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "L2 regularization(beta = 0.00379) test accuracy: 85.0%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1881.184570\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 27.9%\n",
      "Minibatch loss at step 500: 134.915802\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.6%\n",
      "Minibatch loss at step 1000: 12.085148\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 1500: 1.258995\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 2000: 0.287766\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 2500: 0.191501\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 3000: 0.177506\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "L2 regularization(beta = 0.00483) test accuracy: 85.1%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2302.980225\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 30.0%\n",
      "Minibatch loss at step 500: 88.345657\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 1000: 4.235043\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 1500: 0.420566\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 2000: 0.229875\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 2500: 0.213084\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 3000: 0.207794\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "L2 regularization(beta = 0.00616) test accuracy: 84.9%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2746.396729\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 30.4%\n",
      "Minibatch loss at step 500: 48.387135\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 1000: 1.232536\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 1500: 0.289526\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 2000: 0.257298\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 2500: 0.249778\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 3000: 0.245604\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "L2 regularization(beta = 0.00785) test accuracy: 85.2%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 3427.964600\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 26.2%\n",
      "Minibatch loss at step 500: 21.060846\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1000: 0.474744\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 1500: 0.311963\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 2000: 0.300686\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 2500: 0.295436\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 3000: 0.292137\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.9%\n",
      "L2 regularization(beta = 0.01000) test accuracy: 85.0%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "smaller_train_dataset = train_dataset[:(batch_size * 5), :]\n",
    "smaller_train_labels = train_labels[:(batch_size * 5)]\n",
    "\n",
    "for beta_val in beta_vals:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        print(\"Initialized\")\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (smaller_train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch\n",
    "            batch_data = smaller_train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = smaller_train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to find the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : beta_val}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "            if step % 500 == 0:\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "                \n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        print(\"L2 regularization(beta = %.5f) test accuracy: %.1f%%\\n\\n\" % (beta_val, test_accuracy))\n",
    "        accuracy_val.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best beta=0.001438, accuracy=92.8%\n"
     ]
    }
   ],
   "source": [
    "print(\"Best beta=%f, accuracy=%.1f%%\" % (beta_vals[np.argmax(accuracy_val)], max(accuracy_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEMCAYAAADd+e2FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxU5b348c83+0oWsidAIGyyI2FzQVBcKipudddre61Lb6vXtr+2t5td7G1vq9fW3qqlVm3dFa3gVhE1gApIWMIqBMgQIBAy2ci+zfP7YyYYYpZJMmeW5Pt+vXiRzJlzzncmT77z5Hue8zxijEEppVTgCfJ1AEoppfpHE7hSSgUoTeBKKRWgNIErpVSA0gSulFIBShO4UkoFKE3gasgQkQgRMSKS5etY+kpENojILQPY/4CIzPdwTOEiUisiGZ48rnKfJnA/4vplaP/nEJGGDt/fPIDjDuiXXwU+Y0yOMWb9QI7RuR0ZY5qMMTHGmJKBR6j6I8TXAagvGGNi2r8WERtwhzFmte8i8g4RCTHGtPo6joHw19fgr3Epz9AeeAARkWAR+amIHBQRu4g8LyLxrm3RIvKSiFSISJWIbBSRBBF5GJgNPOnqyT/cxXFDROQ1ESl17fuRiEzosD1aRB4VkcMiUi0ia0QkxLVtoatnVi0ixSJyk+vx03prInK3iKx2fd1eyrhHRA4AO12PPy4iR0TkpIh8JiLzOsX4gOu1nxSRTSKSJiJ/E5Ffd3o9q0Tknh7eyitFxCYiZSLya3GKch13XIfjZIlIfft73Okcd4vIhyLyZxGpBH7oevwuEdnr+jm8LSKZHfZZIiKFrvf4Dx3fIxH5rYg82eG5E0Wky8Tr2pbnOkeZiPxdRGI7bD8uIt8TkV3AyQ6PneNqQx3/0qtz/SzSRCRZRN51HbNCRFaISLpr/y+1I+lUkhKRRBF5wbV/kYh8X0Skw/v1gasdVYmzpLO4h5+RcoMm8MDyPeAi4BwgC2gBHnFtuwPnX1SZQBLwLaDZGPNdYBPO3nyM6/uurABygDTgc+DvHbY9CkzE+QucCPwEMCIyFngL+D0wHJgF7OrD67nMtc9M1/frgamuY60AXhWRUNe2/wKudL3+eOBOoNEV500dEkWG6/15uYfzXg7MAOYANwI3G2PqgeVAx1LTzcDbxpiqbo6zANiG8/1+WESuB/7TdfxUYCvwnCuudFdM9wPJQInrtffXL3H+rKYCE4Afd9p+PXAhzvfyFGNMm6sdxLj+4vsL8AFQhjMfPAGMBEa7dnnEtZ877egJINS174XAPcBNHbYvAPJdMf0f8GTnA6g+MsboPz/8B9iAxZ0eKwLO7vD9aKAeEOCbwBpgShfH2gDc0odzpwEOIALnL2QLMKGL5/0CeLGbY5x2TuBuYLXr6wjAAGf1EIO4XtsE1/eHgIu7ed5B4FzX998DXu/mmO3nXdjhse/gTNIA5wH7O2zbAVzRzbHuBvZ1euwjnB8G7d+3v3epOD9wPuqwLQg40f4eAb8FnuywfSLQ6s7PELgBWN/h++PATZ2ecxw4p9NjtwH7gcRujjsPONbDz7T9/cwCwoE2YEyH7fcB/+rwfu3ssC3RtW+8r37HBsM/7YEHCFcPcwTwjutP0CqcPbwgnD2av+FM4MtdZYj/FpFgN48d4vqT+KCInMTZAxfXcdNx9uwPdLHriG4ed9fhTnH8l6v8UA1U4kwQSa7XntnVuYwzG/yDL3rOtwDP9uG8h4D2URRrgWARmS8iM3C+9nfdjR8YBTzR4edTBrTiTHAZHZ9vjHEAR3uJs0sikiEir4rIUdfP60mcfwX0FFvnY8wFHgaWGmMqXI/FishT4iyFnQRWdXHc7qThbIvFHR47hPPn1u54h6/rXf/HoPpNE3iAcCWqo8D5xpj4Dv8ijDF24xwR8DNjzEScf6p+FWfPDJw9nZ58DeefvIuAOJy9P3Am8WM4k1BOF/sd7uZxgDogqsP3aV29rPYvRORC4NvAVThLJIlAAyAdXnt35/oHcK2IzML5ofJ2N89rN6LD1yNxljM6fxjcCrxkjGnp4Tid39fDwO2dfj6RxpjNON/HU8MXRSSI05ObO+9Xu9+7nj/FGDMMZ/lMeontFFeZ6TWc5ZCOJa8fumKc7TruRZ2O21M7Oo7zr7aRHR4bST8/pJR7NIEHlieA34rICAARSRGRy11fLxaRSa7EcBJn0nW49isFxvRw3Fic9eRyIBp4sH2DK4H9A/ijiKS6LoKd4+rdPwtcJiJXuXrxySIyzbXrNpxJNUJEJgK39/LaYnGWG8qAMJw13ogO258E/ltExojTzPaLi8aYg8Bu4GngZWNMcy/n+oGIxIlINs5rBR3r5f8ArsNZG/9HL8fp7AngJ+K6ACzOi8jXuLatBOaKyKXivAD8HSChw77bgEUikikiCcAPejhPLFALnBSRka5juUVEwoDXgb8YY1Z0cdx6oEpEknBe6+io23ZkjGkC/onzZxQtIjk4SyjPuRub6jtN4IHld8Bq4EMRqQE+Bc50bcvEeeGvBueojnf4IjE9AtwmIpUi8rsujvs3nInzOM6678edtt+Ls3yxFWeS/xXOnvF+YCnwI6AC5wWqyR1iDXEddxm9/yK/ibOEcQBnTdvu2rfdb3H2rD/E+QH1BM66a7u/47yg11v5BNdxClzxvtoxNmPMAWAvUGOM+cyNY51ijHkR58W5110liG04/7LBGHMM54fCo67XloXzvW7qENNbOD+INgBv9HCqn+G8UFuNM2m+1ocwxwBzcX6IdRyNkgI8hLNkUo6zDbzTad/e2tFdrv8P4fw5PQk834fYVB+J64KCUgFNRC4CHjPGjPXAsV4AdhtjHuz1yf0/RwjOD8zLzQBvsFFDl/bAVcBzlQXuxdnTH+ixxuIc3vj0QI/VxbG/4irdRAAP4CxXbPb0edTQoQlcBTTXaJFKnPXbPw/wWL/DWSb6pTHGiotvC3AOBT0BXABc5Ua9XqluaQlFKaUClPbAlVIqQGkCV0qpAOXV2QiTkpJMdnZ2v/atq6sjOjraswEp5aLtS1lpoO1r8+bNdmNMcufHvZrAs7Ozyc/P79e+eXl5LFy40LMBKeWi7UtZaaDtS0QOdfW4llCUUipAaQJXSqkApQlcKaUClCZwpZQKUJrAlVIqQGkCV0qpAKUJXCmletDU2saW4kr8cdoRr44DV0qpQFJR18xdz+azyVbJvDGJ/PqqqeQk+88qcNoDV0qpLhTZ67j6sU8oOFLNv58zmt0lJ/nKH9bxh9X7aGpt83V4gPbAlRrU7LVNPPOJjY1F5YxIjCInOYac5BjGpkQzMjGasBDtw3Xls6IK7nw2nyARXvzGXGaNSuSu88bw4Ft7+MPqQlYWlPDrK6cyP2e4T+PUBK7UIHS4op6/rjvIy5sO09zmYFpmHJ/uL+f1LV9Mcx4SJIwc/kVSz0mOJiclhpykGOKiQn0Y/Req6ptZW2jneHUD1+eO9Epcb2w9yveXbycrMZKnb5/NqOHOOUxSYiN49MaZXDsri5+8sZMb/7qBa2dl8aNLzyAxOszyuLqiCVypQeTz4yd5Iu8Ab24/RpDAVTMzuXNBDmNTnHXbmsYWiux1HCirZf+JWg6ccH6dt/cELW1fXKRLign/IqEnxzAuJYapmXEkWJyoHA7DrpKT5O09Qd6+MrYWV+JwhbVsbRE/u3wSl09LR0Q8fm5jDI9+sJ9HVu9j3phE/nJLbpcfGAvGJ7Pq/gU8+kEhy9Ye5IM9pfx4ySSuOTPTkrh6oglcqUFgk62Cx/MO8OHnJ4gKC+brZ2fz9XNGkx4XedrzYiNCmZYVz7Ss+NMeb21zcLiygQMnajlQ1v6vjre3H6O6oeXU80YmRjEtK47pWfFMHxHPlMxhRIUNLI1U17ewtrCMvL1lrNlXhr3Wuc7ztKw4vrVoLOdNSCE0WPjJGzu598WtLN98hAeXTmHk8KgBnbejptY2/uu1Hby+9SjXnJnFb66e2mN5KSI0mO9fMpGlMzL50T938L1XC1i++bDXL3JqAlcqQDkcho/2nuDxvAPkH6okMTqM7144nlvnjyI+qm895ZDgIEYnRTM6KZrFpJ563BhDRV0ze4/XsP1oNQWHq9haXMVb248BECQwLiWW6SPimJYVz/SseCakxfaY/BwOw+5jrl723jK2uHrZcZGhLBifzKIJySwYn0xSTPhp+/3zm2fz7HobD63ax4WPrOG+xeP4xrljCA0eWB2/qr6Zu57dzMaiCr574Xi+df5Yt3vSE9JiefWu+bycf5jfvLOHr/xhHd9clMM9C3MIDwkeUFzucCuBi8j9wB2AAXYAXwOeAM4Dql1Pu90Ys82KIJVSX2hpc/DW9hKeyDvI3tIaMuMj+cUVk7kudwSRYZ5NGiLC8Jhwzhobzlljk049XlbTxPYjVRQcqWb7kSre313KK/lHAAgLCWJS+jCmZ7mS+oh4kmLC+Hi/nby9zp52ey97amYc/7FoLAsnpDBjRDzBQd0nzuAg4fazR3PxlDR+sXI3v/vXXlZsLeG/r57CrFGJ/Xp9h8rr+NrTmzhS2cAfb5jB0hmZfT5GUJBw45yRLD4jlQff3u28yLmthF9fZf1Fzl7XxBSRTOBjYJIxpkFEXgHeARYCbxljlrt7stzcXKPzgSt/FAjtq6G5jVfyD7Ns7UGOVjUwPjWGexbmcNm0jAH3QgfKGMORygYKjlRRcNiZ2Hceraa++fThdnGRoZw7LolFE1JYMD6Z5Njwbo7Yu9W7S/nZip2UVDdy09yR/ODiiX26yJlvq+DOZzdjjGHZbbnMzu7fh0Bna/eV8ZM3dlJcUc81Z2bx4yVnsH3TpwOdD3yzMSa38+PullBCgEgRaQGigJJ+R6KU6pO6plae+riIpz+1UVHXzKxRCfxy6WQWTUghqIceqzeJCCMSoxiRGMVl0zIAaHMY9p+opeBIFWU1Tcwbk8j0rHhCPPRhs3hSKvNzhvPI+/t46pMiVu0qdfsi58qCEr73agGZ8ZE8dftsRid5bjWm9oucf/qwkL+sOciHn5dy9RjhPGM8fpHTrVXpReQ+4NdAA7DKGHOziDwDzAeagA+AHxpjmrrY907gToDU1NRZL730Ur8Cra2tJSbGf+6AUoOLv7YvhzH8cUsTBWVtTE8OZsmYUMYnWF9bDTSHTrbxzK5miqodTEkK5rZJYaREffmDwhjDmwdbeL2whfEJQdw7M4KYMOs+BI/WOHhmVxOFVQ5+Oi+CnPj+/ewWLVrUZQ/cnRJKAvAacD1QBbwKLMeZtI8DYcAy4IAx5pc9HUtLKMpf+Wv7emLNAX777uf8/PJJ3H72aF+H49faHIbnNhzi9+/tpaXN8aWLnM2tDn70zx0s33yEK2dk8D/XTvPKhUaHw/DEPz/km9dc0O9jdFdCcedvmcVAkTGmzBjTArwOnGWMOWacmoCngTn9jk4p9SWbbBX8/r29XDo1jX87K9vX4fi94CDh387KZvV3zuP8iSn87l97WfLoOvJtFVTXt/BvT33G8s1HuO+CcTxy/QyvJG9wXuScNNyac7lTAy8G5olIFM4SygVAvoikG2OOibOocyWw05IIlRqCymub+PYLW8lKiOS310zz+g0igSwtLoLHb5nF6t2lPLByF9c+sZ7k2HCq6pv53+umc/WZWb4O0WN6TeDGmI0ishzYArQCW3GWTN4VkWRAgG3A3VYGqtRQ4XAYvvNKARV1zbz+zbMYFuEft7UHmvaLnH9YvY9Vu0v5041zmTfGt3OXeJpbo1CMMQ8AD3R6+HzPh6OUenzNAdbsK+NXV05hSmacr8MJaNHhIfx4ySR+vGSSr0OxhE5FppQf2XiwnIdX7eWyaencMnekr8NRfk4TuFJ+wl7bxLdf3Mqo4dH85uqpWvdWvdIErpQfcDgM97+8jaqGFv7vppnEat1buUETuFJ+4M8f7WddoZ2fXz6ZyRla91bu0QSulI99esDOI6v3sXRGBjfOGeHrcFQA0QSulA+V1TRx30vbyE6K5r+v0rq36hudD1wpH2lzGP7z5a2cbGjh2X+fQ3S4/jqqvtEWo5SP/OnDQj7ZX87/XDOViWnDfB2OCkBaQlHKBz7Zb+ePHxRy9cxMrsvVurfqH03gSnnZiZON3PfSVnKSY3jwqila91b9piUUpbyozWG496Wt1DW18cI3zhzwgsBqaNPWo5QX/XH1PjYcrOChr05nfGqsr8NRAU5LKEp5ydp9Zfzpo/1cOyuLa2cNnilNle9oAlfKC0pPNnL/y9sYlxLDr5ZO8XU4apDQBK6UxVrbHHz7ha00tLTx2M1nEhmma1oqz9AauFIWe3HTYT6zVfDI9dMZm6J1b+U52gNXymIFh6tIiQ3nqpla91aepQlcKYvZ7HVkJ0X7Ogw1CGkCV8pitvI6Rg/XBK48TxO4UhaqaWzBXtusPXBlCU3gSlnIZq8HYHRSlI8jUYORJnClLFRUXgegPXBlCU3gSlnIZncm8FGJmsCV52kCV8pCNnsd6XERevOOsoQmcKUsVFReR7aOQFEW0QSulIV0DLiykiZwpSxSXd9CZX0L2cN1BIqyhiZwpSxi0xEoymKawJWySHsCH60JXFlEE7hSFimy1yECIxO1hKKsoQlcKYvY7HVkxEUSEapDCJU1NIErZZGi8nqy9RZ6ZSG3EriI3C8iu0Rkp4i8KCIRHbY9KiK11oWoVGCy2XUMuLJWrwlcRDKBe4FcY8wUIBi4wbUtF0iwNEKlAlBlXTPVDS16AVNZyt0SSggQKSIhQBRQIiLBwO+B71sVnFKB6tQkVtoDVxbqNYEbY44CDwHFwDGg2hizCvgWsNIYc8zaEJUKPO2TWOkYcGWlXhc1FpEEYCkwGqgCXhWR24CvAgvd2P9O4E6A1NRU8vLy+hVobW1tv/dVqjeebl95hc0IYNu5iSNB4rHjqsBkVf5yZ1X6xUCRMaYMQEReB34BRAL7RQQgSkT2G2PGdt7ZGLMMWAaQm5trFi5c2K9A8/Ly6O++SvXG0+3rtWNbyUqsZPH5izx2TBW4rMpf7tTAi4F5IhIlzmx9AfC/xpg0Y0y2MSYbqO8qeSs1VOkIFOUN7tTANwLLgS3ADtc+yyyOS6mAZYzBZq/TESjKcu6UUDDGPAA80MP2GI9FpFSAK69rpqapVXvgynJ6J6ZSHtY+AkV74MpqmsCV8rAiHUKovEQTuFIeZiuvIzhIyEqI9HUoapDTBK6Uh9ns9YxIiCQ0WH+9lLW0hSnlYUW6DqbyEk3gSnmQMQabrkSvvEQTuFIeVFbTRH1zm45AUV6hCVwpD9IRKMqbNIEr5UGnFjLWEoryAk3gSnlQkb2e0GAhIz6i9ycrNUCawJXyIJu9jhGJUYToEELlBdrKlPIgW3mdlk+U12gCV8pDHA7XEEK9gKm8RBO4Uh5SWtNIY4tDE7jyGk3gSnlI+xBCLaEob9EErpSH2Oz1AGQnRfk4EjVUaAJXykNs5XWEhQSREaezECrv0ASulIcU2esYlRhFkK5Cr7xEE7hSHmKz1zFK69/KizSBK+UBDofhUEU9o7X+rbxIE7hSHlBS3UBzqw4hVN6lCVwpD2gfgaJDCJU3aQJXygPaZyHUHrjyJk3gSnmAzV5HeEgQacN0FkLlPZrAlfKA9mXUdAih8iZN4Ep5gHMhYx2BorxLE7hSA9TmMByuaND6t/I6TeBKDVBJVQPNbQ4dgaK8ThO4UgOkCxkrX9EErtQAnVrIWBO48jJN4EoNUJG9jqiwYFJiw30dihpiNIErNUDtk1iJ6BBC5V2awJUaIFu5TmKlfMOtBC4i94vILhHZKSIvikiEiPxNRApEZLuILBeRGKuDVcrftLY5OFxRT7aOQFE+0GsCF5FM4F4g1xgzBQgGbgDuN8ZMN8ZMA4qBb1kaqVJ+6EhlA60OoyNQlE+4W0IJASJFJASIAkqMMScBxFn4iwSMNSEq5b+KdASK8qGQ3p5gjDkqIg/h7GU3AKuMMasARORp4FJgN/DdrvYXkTuBOwFSU1PJy8vrV6C1tbX93lep3vS3fa22tQBQsreAPJtexFRdsyp/iTE9d5xFJAF4DbgeqAJeBZYbY55zbQ8G/gRsMsY83dOxcnNzTX5+fr8CzcvLY+HChf3aV6ne9Ld9PbBiJ69tOcqOn1+ko1BUtwaav0RkszEmt/Pj7pRQFgNFxpgyY0wL8DpwVvtGY0wb8BJwTb+jUypAFZXXk50Upclb+YQ7CbwYmCciUa569wXAHhEZC6dq4FcAn1sXplL+yWav0xEoymfcqYFvFJHlwBagFdgKLAM+FJFhgAAFwD1WBqqUv2ludXCksp6lMzJ8HYoaonpN4ADGmAeABzo9fLbnw1EqcByurMdh0B648hm9E1OpfrLpLITKxzSBK9VP7dPI6hhw5SuawJXqJ1t5HcMiQkiICvV1KGqI0gSuVD/Z7PWMTtJZCJXvaAJXqp+cCxlr+UT5jiZwN/x85S5ue+ozX4eh/EhjSxsl1Q06AkX5lFvDCIcyh8PwZkEJlfXN1DS2EBuh9U4FhyvqMUYvYCrf0h54L3YfO0l5XTMOA1uLq3wdjvITupCx8geawHuxrtAOQJDAJluFj6NR/uLUQsZaQlE+pCWUXqwrLGNiWiyhwUGawNUpRfZ6EqJCidMhhMqHtAfeg/rmVvJtlSwYn8zs7ES2Ha6iudXh67CUH2hfyFgpXwqYBN7U5v0FfzYerKC5zcG545KYnZ1AY4uDnSXVXo9D+R9beZ1ewFQ+FxAJ/K5n8/njlkavn3dtYRnhIUHMzk4kNzsRgHwtowx5Dc1tHKtu1CGEyucCIoGPTYnh8woH1fUtXj3vukI7c8cMJyI0mOTYcEYnRbPJVunVGJT/OVTRPgIlyseRqKEuIBL4RZPScBj4cG+p185ZUtXA/hO1LBiXdOqx3FEJ5NsqcDh0/eahzKaTWCk/ERAJfGpmHAnhwqpd3kvg6wrLADh3XPKpx2ZnJ1JZ38JBe63X4lD+p8heD+gYcOV7AZHAg4KEmSnBrNlXRmNLm1fOubbQTuqwcManxpx6bPZoZx1cyyhDm81ex/DoMIbpXbnKxwIigQOcmRpMfXMbn+y3W36uNofhk/12zh2XfNpMc9nDo0iKCWNTkV7IHMps5TqJlfIPAZPAJyYGExse4pUyyo6j1VTVt3Buh/o3gIiQOyqRTYc0gQ9ltnJdyFj5h4BJ4CFBwqKJKazeU0qbxRcR1+0rQwTOGZv0pW2zRydyuKKB49XeH9aofK++uZXSk02M1hEoyg8ETAIHuGhyKuV1zWwptrYGva7QzpSMOIbHhH9p2+zsBEDnRRmqbHoBU/mRgErg541PJiw4iFW7jlt2jprGFrYUV36pfNJuUvowosKC9YaeIap9EistoSh/EFAJPDYilLPGDmfV7lKMsaaMsv5AOa0Oc9rwwY5CgoM4c2SCjkQZonQaWeVPAiqBg/OmnkPl9ewrtWYs9rpCO1FhwcwaldDtc3KzE9hz/CQnG717Z6jyPZu9juTYcGLCdSJP5XsBl8AXT0pBBMvKKOsKy5g/ZjhhId2/NbOzEzEGthzSXvhQYyuv0znAld8IuASeEhvBzBHxrNrt+eGExeX12Mrru61/t5s5Mp7gICFfyyhDTpG9XudAUX4j4BI4wEWT09hxtJqSqgaPHndt++3z47uuf7eLCgthSsYwPtMLmUNKTWML9tomrX8rvxGYCXxSKgDve7gXvq6wjMz4SMa48Quam51IweEqmlq9c2u/8r1D5c4hhFpCUf4iIBP4mOQYxqbEsGq35+rgrW0OPt1fzoLxSafdPt+d2dmJNLU62Hn0pMdiUP5NR6AofxOQCRycvfCNBys8Nkd4wZEqappaux0+2Fmu3tAz5LRPI6tjwJW/CNwEPjmNVofho70nPHK8tfvsBAmclTPcrecnxYQzJilab+gZQorK60gbFkFkWLCvQ1EKCOAEPi0zjtRh4R4ro6wtLGNaVjzxUWFu7zM7O5H8Q5W6wMMQYbPX6QgU5VcCNoEHBQkXTkolb+/A5wivrm+h4HAVC3oZfdJZbnYCVfUt7C/TBR6GAlt5va7Co/yKWwlcRO4XkV0islNEXhSRCBF5XkT2uh57SkS8Prv9RZPSqG9u49MDA5sj/NMDdhyG05ZPc8fs7PYFHrSMMthVN7RQUdes9W/lV3pN4CKSCdwL5BpjpgDBwA3A88BEYCoQCdxhYZxdmjdmuEfmCF9baCc2PITpI+L7tN+o4VEkx4ZbfkPPCxuLuffFrdQ2tVp6HtU9m45AUX7I3QkdQoBIEWkBooASY8yq9o0i8hmQZUF8PQoLCWJhhznCg4N6H/7XmTGGtfvKmJ8znNDgvlWURITZ2Ql8ZuEKPY0tbTy0ai8Vdc0cKq/jma/NISHa/Tq98oz2WQi1hKL8Sa8J3BhzVEQeAoqBBmBVp+QdCtwK3NfV/iJyJ3AnQGpqKnl5ef0KtLa2tst9s2jFXtvMUys+ZFxC30cHHK9zcLSqgQsy2voVW3xLC0ermnnt3Q8ZHun5SwqflrRSUdfMJdmhrC6uZskjq/l/uREkRATs5Quv22lvZc2RVs7KCGF6cjBBXYzz7659tftofzMC2HbmU7Kn7x0FNbT11r76q9cELiIJwFJgNFAFvCoitxhjnnM95TFgrTFmXVf7G2OWAcsAcnNzzcKFC/sVaF5eHl3tO6uxhSd3vk9ZeAbfWHhGn4/7909twC7uWHI2I4f3fYRB0tFqXvj8Y0IzJrJwekaf9+/No499wpikEB678zw2FlVwx9838b/b4fl/n9OveIei/3v8U/KPV7LpeBuZ8ZHcPG8E1+eOOG3Bju7aV7s3jm8lI76Siy5Y5IWI1WDTW/vqL3e6cYuBImNMmTGmBXgdOAtARB4AkoHveDwyN8VGhHJWThLv7TrerznC1xWWMWp4VL+T4cS0WKLDgi1Z6HhXSTVbiqu4ae5IgoKE+TnDeeEb86hpbOXaJz5lX2mNx8852BytaiD/UCX3Lx7PYzefycjEKH73r73M/82H3P/yNrYUV7rVborKdRIr5X/cSeDFwDwRiRLnPeYXAHtE5A7gYuBGY4zDyiB7c9HkVA6V11N4om/D+Wu+R8cAABKXSURBVJpbHaw/UN7r7IM9CQkO4sxRCZaMRHluQzERoUF8ddaIU49NHxHPK3fNB+C6v6yn4HCVx887mLxZUALAVTMzuXRqOi/eOY/371/ADXNG8P7uUq5+7FMu+9PHrDnSQkNz98NRbXZdyFj5n14TuDFmI7Ac2ALscO2zDHgCSAXWi8g2EfmZlYH25MIznJNb9XWO8C3FldQ1t7HAzdvnu5M7KpG9pTVUN3hugYeTjS28sfUoV0zPIC7q9BGa41NjWX73WcRGhHDTXzcMeBjlYLZiWwkzR8af9hfWuNRYfrl0Cht+dAG/unIKLW0Ont7ZzLzffMCDb+0+NedJu8q6ZqobWvQCpvI7bl0JM8Y8YIyZaIyZYoy51RjTZIwJMcbkGGNmuP790upgu5MyLIKZI/s+R/i6wjKCXaWJgZg9OsHjCzy8vvkIDS1t3Dovu8vtI4dHsfzus8iIj+T2pzex2oL50QNdYWkNe46d5Ipurk3EhIdw67xRvPefC/ivORGcMy6JZz61seihPG576jPe3+0c3VSk62AqPzVohjJcNCmN7Uf6Nkf4ukI7Z46MJzZiYPcgzRgRT0iQeKyMYozhuY3FTM+KY2pWXLfPSx0WwSt3zeeMtFjuem4zK7Yd9cj5B4uVBSUECSyZlt7j80SECYnB/PmmM/n0h+dz/+Lx7D1+km/8I58Fv/uIxz46AOgYcOV/Bk8Cn+wso6ze415PtKKumR1Hq92efbAnUWEhTM6M89gNPRsOVrD/RC23zBvV63MTosN4/hvzmJ2dwH++vI1nNxzySAyBzhjDyoISzspJIiU2wu39UoZFcN/icXz8g/N53HXRc/WeUsKCgxiRGGlhxEr13aBZmTUnOYac5GhW7SrltvnZvT7/4/12jKHP8590Z052An9ff4im1jbCQwY2W91zGw4RFxnK5W4OS4wJD+GZr83hWy9s4adv7KSmsYVvLhw7oBgC3fYj1Rwqr+c/+vk+hAYH8ZWp6XxlajqFpTWcbGwZ8M9VKU8bND1wcE4xu+FguVtzhK/bV0ZcZChTM7svUfRFbnYiza0OdhypHtBxTpxs5L1dx/nqrCwiQt1PGBGhwTx+yyyWzsjgd//ay2/f/bxfwyoHixXbSggLDuLiKWkDPta41FhmjUr0QFRKedbgSuCTUt2aI9wYw7pCO+eMTerX7fddyR3VvsDDwMooL206TKvDcLMb5ZPOQoODeOS6Gdw8dyRPrDnAj9/YSdsQnOq2zWF4a3sJCyckExfp9TnWlPKaQZXAp2fFkxLb+xzhhSdqOX6ycUDjvzsbHhNOTnL0gC5ktrY5eGFjMeeOS+r3kLWgIOHBK6dwz8IcXthYzP0vb6OlzafD9L1u48FyTtQ0ccUMz98Zq5Q/GVQJvH2O8DW9zBG+dp97q8/31ezsRPJtFf1e4GH1nhMcP9nIrf3ofXckIvzgkon84JKJrCwo4a5nNw94zvRAsrKghOiwYC6YmOrrUJSy1KC5iNnuoslpPL+xmPUHylk0MaXL56wrtJOTHE1mvGdHFeRmJ/LSpsMUnqhlQlpsn/d/fuMh0uMiOL+buPvqnoU5DIsM4Sdv7OSCh9cwMjGKxOgwEqJDSYwKIyE6zPl9lOv/6DASo8ICesmwptY23t15nIsmpwX061DKHYMugc9vnyN89/EuE3hjSxsbi8q5YfZIj597jmuBh89sFX1O4AfLallXaOe7F44npI/T2vbk5rmjSIoJZ/nmI1TWNbPn+Ekq65qpamihu2ucEaFBX0rwc8ckcvPcgf1l4A1r99mpbmjR8okaEgZdAm+fI/z93aU8eOWX5wjPt1XS2OJgwXjP1b/bjUiMJCU2nHxbRZ/LIM9vLCYkSLh+zojen9xHF09O4+LJp4/GaHOYU6vMVNY3O/+va6ai3vV/XQtV9c7vPz9ew9s7jnHJ5LTTZvDzRysLSkiICuWcsZ7/+SrlbwZdAge4cFIqbxaUsO1w5ZeGf60rLCM0WJg3ZmC3z3fFucBDYp9v6GlobuPV/MNcMiWtTzedDERwkJDo6mH3ZldJNUse/Zj3dpVy01zP/+XiKXVNrby/+zjXnJnV58U5lApEg7KVL5yQTGiwdLnU2tpCO7mjEokKs+aza3Z2AkerGjjah1v639xewsnGVrfuvPSFSenDGJ0UzTs7jvk6lB6t3lNKY4uDpTMyfR2KUl4xKBP4sIhQ5ncxR/iJmkb2HDvJuRaUT9rluurg+X0YTvjchkOMS4lh7mj/vFlERLh0ahqfHrBTXtvk63C6tXJbCelxEafG5Cs12A3KBA7Om3ps5fXs7zBH+MeFzmlXBzp9bE/OSB9GTHiI2+PBCw5Xsf1INbfOH4V0sdSXv1gyNQOHgfcGuIC0VSrrmlmzr4zLp2cQ5KGbs5Tyd4M2gV84yTVHeIdpVtcV2hkeHcak9GGWnTc4SJwLPBS5Vwd/bsMhosKCuWqmf//Zf0Z6LKOTonl7R4mvQ+nSuzuP0+ow3U4dq9RgNGgTeOqwCGaMiD+1yIPD4bp9flyS5T202aMSnAs89DInS1V9MysLSrhyZuaAp7S1moiwZGo66w+U+2UZZcW2o4xJjmZyhnUfzkr5m0GbwME5xWzBkWqOVTfw+fEa7LVNHpk+tjftdfDNxT2XUZZvPkJTq4NbAmB8NcClU9NxGPhXH1c+strx6kY+s1WwdHqmX5ehlPK0wZ3AJznHPq/eXcraQtft8x6c/6Q7M0bEExosfNZDGcXhMDy34RC5oxKYFCC9xjPSYxnjh6NR3tpegjHozTtqyBnUCXxsSgxjkqNZtbuUdYVlTEiNJXWY9eOsI8OCmZIZ1+NIlE8O2LGV13Pr/MDofUP7aBRnGcXuR2WUFdtKmJoZp2tWqiFnUCdwcPbC1x8oZ1NRpSV3X3ZndnYi249UdzuJ1LPrDzE8OoxLPDBftTctmZbuGo3iH2WUg2W17DhazVLtfashaPAn8MnOOcKb2xxeqX+3m52dSHObgx1Hv7zAQ0lVA6v3lHLd7BEBt8rLxDRnGeXt7f5RRllZUIIIXDZNE7gaegZ9Ap+RFU9ybDhhIUHM8eKNMrNcN5N8VvTlMsqLnxVjgJvm+O9t6d0REZZMS2fDQd+XUdrXvZw7OpG0OO9MQaCUPxn0CTwoSPiPhTncee6YPi1RNlCJ0WGMTYn5Uh28udXBS5sOc/6EFEYkRnktHk86NRplp2/LKLtKTnKwrI4rpvv3GHqlrDLoEzjA7WeP5nsXT/D6eWdnJ5J/qPK0BR5W7T5OWU2T38574o6JabGMSfb9aJSVBSWEBAlfCbDrCEp5ypBI4L4yOzuBmsZW9pbWnHrs2fWHGJEYyQIPrwbkTe039fiyjOJwGN4sKOG88ckkuDGjolKDkSZwC83uNLFVYWkNG4squHnuKI8tpuwr7aNRfFVG2WSr4Fh1o479VkOaJnALZSVEkjYs4tRK9c9tOERYSBDX5Xp+0QZvm5DqLKP4ajTKyoISIkKDWHyGrnuphi5N4BYSEXKzE9hkq6CuqZXXthxlydR0txZR8HciwmVT09lYVE5ZjXfLKC1tDt7ZcYwLJ6URHT4o1yRRyi2awC02OzuRY9WN/Pmj/dQ2+e+iDf1x6TTfzI3ycaGdyvoWnXlQDXmawC3WXgf/y9qDTEofxpkj430ckedMSI0lJzmad7xcRllZUEJcZCjnBfCFYKU8QRO4xSakxRIbHkKbw3DLPP9etKGv2kejeLOM0tDcxnu7jvOVKWmEhWjzVUOb/gZYLDjIWQePDQ8ZlPN1LJmW4dUyygefl1Lf3KblE6VwM4GLyP0isktEdorIiyISISLfEpH9ImJExHuzRAWgX1wxhefumDsoL7iNT40hJzmat7d7Z6WeldtKSIkNZ+6Y4V45n1L+rNcELiKZwL1ArjFmChAM3AB8AiwGDlka4SAwcngU00cMntp3R865UTL4rKiCEzWNlp6ruqGFvL1lXDYtI+DH0SvlCe6WUEKASBEJAaKAEmPMVmOMzbLIVMBY4pob5T2Lb+p5b+dxmtscevOOUi69JnBjzFHgIaAYOAZUG2NWWR2YChzjU2MYmxLD2xbPjbKi4CijhkcxPSvO0vMoFSh6LcqKSAKwFBgNVAGvisgtxpjn3DmBiNwJ3AmQmppKXl5evwKtra3t977KepNjm1l5oJY33vuQ+HDPXxuvanLw6f4GLssJZc2aNR4/vrYvZSWr2pc7V9UWA0XGmDIAEXkdOAtwK4EbY5YBywByc3PNwoUL+xVoXl4e/d1XWS/jjBpWPLKWmmFjuHJ+tseP//QnRRh2c9/S+YxNifX48bV9KStZ1b7c6SoVA/NEJEqcg5gvAPZ4PBIV0ManxjI2JYa3LLqpZ8W2Es5IH2ZJ8lYqULlTA98ILAe2ADtc+ywTkXtF5AiQBWwXkSctjVT5vSVT0/nM5vnRKMXl9Ww7XKVjv5XqxK1ipTHmAWPMRGPMFGPMrcaYJmPMo8aYLGNMiDEmwxhzh9XBKv+2ZFo6xsNTzBpjePLjgwBcPj3dY8dVajDQOzGVx4xPjWVcSoxHp5j94weF/GP9IW6ZN5KshMBcgk4pq2gCVx51aXsZ5eTAyyh/+qCQP6wu5NpZWfzyiikeiE6pwUUTuPKoU2WUAc6N8ueP9vPw+/u4emYm/3PNNIL0zkulvkQTuPKo9jLKQEaj/GXNAX7/3l6Wzsjg91+drrfNK9UNTeDK45ZMS2dTP8soT647yG/e/ZzLpqXzsCZvpXqkCVx53JKpzjLKu30cjfLMJ0U8+PYeLp2axh+un0FIsDZPpXqivyHK48alxjI+tW9zozy73sbP39zNxZNT+eMNMzV5K+UG/S1Rlrh0qvtllBc2FvPTFbtYfEYKf7rxTEI1eSvlFv1NUZZwt4zy8qZifvTPHSyakMyfbz5Tl0lTqg/0t0VZ4lQZpYfRKK/mH+aHr+9gwfhkHr9lFuEhwV6MUKnApwlcWWbJ1Aw2HaqgtIsyyj+3HuH7r23n7Jwklt06i4hQTd5K9ZUmcGWZJdPSnGWUThczV2w7yndfKWDe6OH89bZcTd5K9ZMmcGWZsSmxTEiN5Z0dX9TB39pewv0vb2N2diJ/uz2XyDBN3kr1lyZwZalLp6afKqO8u+MY9720jVmjEnjq9tlEhbmznohSqjuawJWl2ssoP31jJ99+cSvTs+J4+mtziA7X5K3UQGkCV5ZqL6Os2l3KlMw4/v71OcRo8lbKIzSBK8v9x/ljuWRyGn//+hxiI0J9HY5Sg4Z2hZTlrpieocuhKWUB7YErpVSA0gSulFIBShO4UkoFKE3gSikVoDSBK6VUgNIErpRSAUoTuFJKBShN4EopFaDEGOO9k4lUA4U9PCUOqO5mWxJg93hQ1uvpNfnzufp7rL7u15fn9/bcgWzX9uXdcw3kWFa1MXee19NzrGxfo4wxyV961BjjtX/Asv5uB/K9Gau3XrO/nqu/x+rrfn15/kDaT2/btX1591wDOZZVbcyd5/XShrzevrxdQnlzgNsDkTdfkyfP1d9j9XW/vjx/oO1H25f/nGsgx7KqjbnzvJ6e4/X25dUSykCISL4xJtfXcajBSduXspJV7SuQLmIu83UAalDT9qWsZEn7CpgeuFJKqdMFUg9cKaVUB5rAlVIqQGkCV0qpADVoEriIRItIvohc5utY1OAiImeIyBMislxE7vF1PGpwEZErReSvIvKyiFzUl319nsBF5CkROSEiOzs9fomI7BWR/SLyQzcO9QPgFWuiVIHKE+3LGLPHGHM3cB1wtpXxqsDiofb1hjHmG8DdwPV9Or+vR6GIyAKgFviHMWaK67FgYB9wIXAE2ATcCAQDv+l0iK8D04HhQARgN8a85Z3olb/zRPsyxpwQkSuAe4BnjTEveCt+5d881b5c+z0MPG+M2eLu+X2+qLExZq2IZHd6eA6w3xhzEEBEXgKWGmN+A3ypRCIiC4FoYBLQICLvGGMcVsatAoMn2pfrOCuBlSLyNqAJXAEey18C/BZ4ty/JG/wggXcjEzjc4fsjwNzunmyM+TGAiNyOsweuyVv1pE/ty9VBuBoIB96xNDI1GPSpfQHfBhYDcSIy1hjzhLsn8tcE3i/GmGd8HYMafIwxeUCej8NQg5Qx5lHg0f7s6/OLmN04Cozo8H2W6zGlPEHbl7KS19qXvybwTcA4ERktImHADcBKH8ekBg9tX8pKXmtfPk/gIvIisB6YICJHROTfjTGtwLeA94A9wCvGmF2+jFMFJm1fykq+bl8+H0aolFKqf3zeA1dKKdU/msCVUipAaQJXSqkApQlcKaUClCZwpZQKUJrAlVIqQGkCV0qpAKUJXCmlApQmcKWUClD/Hw3z5PbJhJ8bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(beta_vals, accuracy_val[20:])\n",
    "plt.grid(True)\n",
    "plt.title(\"Test accuracy by regularization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "beta_vals = np.logspace(-4, -2, 20)\n",
    "hidden_size = 1024\n",
    "accuracy_val = []\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size * image_size), name='train_dataset')\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels), name='train_labels')\n",
    "    tf_valid_dataset = tf.constant(valid_dataset, name='valid_dataset')\n",
    "    tf_test_dataset = tf.constant(test_dataset, name='test_dataset')\n",
    "    beta_regul = tf.placeholder(tf.float32, name='beta')\n",
    "    \n",
    "    # Variables.\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_size]), name='weights1')\n",
    "    biases1 = tf.Variable(tf.zeros([hidden_size]), name='biases1')\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([hidden_size, num_labels]), name='weights2')\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]), name='biases2')\n",
    "    \n",
    "    # Training computation.\n",
    "    hidden = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    hidden = tf.nn.dropout(hidden, rate = 0.5)\n",
    "    logits = tf.matmul(hidden, weights2) + biases2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = tf_train_labels, logits = logits))\n",
    "    loss += beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2))\n",
    "    \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for training, validation, and test data\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    valid_hidden = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(valid_hidden, weights2) + biases2)\n",
    "    \n",
    "    test_hidden = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_hidden, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 468.151947\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 39.1%\n",
      "Minibatch loss at step 500: 32.208839\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 1000: 28.670996\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 1500: 27.288633\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 2000: 25.963497\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 2500: 24.701515\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 3000: 23.501022\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "L2 regularization(beta = 0.00010) test accuracy: 84.4%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 509.122711\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 32.2%\n",
      "Minibatch loss at step 500: 37.804611\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 1000: 35.494335\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1500: 33.314960\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 2000: 31.262632\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 2500: 29.337193\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 3000: 27.527855\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "L2 regularization(beta = 0.00013) test accuracy: 84.3%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 584.327759\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 28.3%\n",
      "Minibatch loss at step 500: 47.856651\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1000: 43.727787\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 1500: 40.334587\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 2000: 37.212940\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 2500: 34.298622\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 3000: 31.627956\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "L2 regularization(beta = 0.00016) test accuracy: 84.7%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 560.007019\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 23.7%\n",
      "Minibatch loss at step 500: 58.958237\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 1000: 53.194782\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 1500: 47.982056\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 2000: 43.272709\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 2500: 39.029266\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 3000: 35.197517\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "L2 regularization(beta = 0.00021) test accuracy: 84.7%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 591.454346\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 33.9%\n",
      "Minibatch loss at step 500: 73.138824\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1000: 64.150650\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 1500: 56.245155\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 2000: 49.308346\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 2500: 43.222549\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 3000: 37.887058\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "L2 regularization(beta = 0.00026) test accuracy: 84.7%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 535.507080\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 29.0%\n",
      "Minibatch loss at step 500: 89.664124\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 1000: 75.881447\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1500: 64.136086\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 2000: 54.233883\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 2500: 45.853729\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 3000: 38.767345\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "L2 regularization(beta = 0.00034) test accuracy: 84.8%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 707.676880\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 34.7%\n",
      "Minibatch loss at step 500: 109.429276\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 1000: 88.399590\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 1500: 71.389206\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 2000: 57.643089\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 2500: 46.541004\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 3000: 37.575806\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "L2 regularization(beta = 0.00043) test accuracy: 83.8%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 670.791626\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 34.4%\n",
      "Minibatch loss at step 500: 133.688736\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 1000: 100.175026\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1500: 76.279076\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 2000: 58.079910\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 2500: 44.220058\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 3000: 33.665901\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "L2 regularization(beta = 0.00055) test accuracy: 84.8%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 669.339966\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 35.6%\n",
      "Minibatch loss at step 500: 155.283585\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 1000: 110.459236\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1500: 77.566444\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 2000: 54.794003\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 2500: 38.708534\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 3000: 27.344973\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.9%\n",
      "L2 regularization(beta = 0.00070) test accuracy: 84.2%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 814.256592\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 29.8%\n",
      "Minibatch loss at step 500: 179.543442\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 1000: 115.346870\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 1500: 74.089851\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 2000: 47.582901\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 2500: 30.555544\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 3000: 19.620541\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.9%\n",
      "L2 regularization(beta = 0.00089) test accuracy: 84.3%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 860.109131\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 33.0%\n",
      "Minibatch loss at step 500: 203.204544\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 1000: 115.602852\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 1500: 65.750580\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 2000: 37.395630\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 2500: 21.264257\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 3000: 12.092080\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "L2 regularization(beta = 0.00113) test accuracy: 84.1%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1024.540039\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 37.8%\n",
      "Minibatch loss at step 500: 221.749725\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 1000: 107.815865\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 1500: 52.520401\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 2000: 25.580290\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 2500: 12.460368\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 3000: 6.078881\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "L2 regularization(beta = 0.00144) test accuracy: 84.4%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1125.653564\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 22.4%\n",
      "Minibatch loss at step 500: 231.061554\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 1000: 92.419373\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1500: 36.953304\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 2000: 14.776538\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 2500: 5.929855\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 3000: 2.416830\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.3%\n",
      "L2 regularization(beta = 0.00183) test accuracy: 85.2%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1201.636719\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 42.2%\n",
      "Minibatch loss at step 500: 228.917099\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1000: 71.193062\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1500: 22.132608\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 2000: 6.898152\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 2500: 2.215927\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 3000: 0.766341\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.3%\n",
      "L2 regularization(beta = 0.00234) test accuracy: 85.3%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1399.791016\n",
      "Minibatch accuracy: 16.4%\n",
      "Validation accuracy: 26.6%\n",
      "Minibatch loss at step 500: 212.798813\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1000: 47.988495\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 1500: 10.854740\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 2000: 2.549198\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 2500: 0.694144\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 3000: 0.270400\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "L2 regularization(beta = 0.00298) test accuracy: 85.1%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1726.206299\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 27.9%\n",
      "Minibatch loss at step 500: 179.568192\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 1000: 26.927189\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 1500: 4.156135\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 2000: 0.776876\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 2500: 0.271140\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 3000: 0.185163\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.1%\n",
      "L2 regularization(beta = 0.00379) test accuracy: 85.2%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2071.644043\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 30.4%\n",
      "Minibatch loss at step 500: 136.050858\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 1000: 12.182952\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 1500: 1.281206\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 2000: 0.306961\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 2500: 0.210196\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 3000: 0.200322\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "L2 regularization(beta = 0.00483) test accuracy: 85.2%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2348.206787\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 30.9%\n",
      "Minibatch loss at step 500: 89.408127\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 1000: 4.272243\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 1500: 0.437061\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 2000: 0.255846\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 2500: 0.226284\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 3000: 0.234488\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.4%\n",
      "L2 regularization(beta = 0.00616) test accuracy: 85.5%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 3124.274902\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 37.8%\n",
      "Minibatch loss at step 500: 48.750217\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 1000: 1.270907\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 1500: 0.328156\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 2000: 0.282231\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 2500: 0.292657\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 3000: 0.268323\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "L2 regularization(beta = 0.00785) test accuracy: 85.4%\n",
      "\n",
      "\n",
      "Initialized\n",
      "Minibatch loss at step 0: 3672.724121\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 29.6%\n",
      "Minibatch loss at step 500: 21.128304\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 1000: 0.503806\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 1500: 0.346475\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 2000: 0.338490\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 2500: 0.321012\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 3000: 0.313970\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "L2 regularization(beta = 0.01000) test accuracy: 85.2%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "smaller_train_dataset = train_dataset[:(batch_size * 5), :]\n",
    "smaller_train_labels = train_labels[:(batch_size * 5)]\n",
    "\n",
    "for beta_val in beta_vals:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        print(\"Initialized\")\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (smaller_train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch\n",
    "            batch_data = smaller_train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = smaller_train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to find the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : beta_val}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "            if step % 500 == 0:\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "                \n",
    "        test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "        print(\"L2 regularization(beta = %.5f) test accuracy: %.1f%%\\n\\n\" % (beta_val, test_accuracy))\n",
    "        accuracy_val.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best beta=0.006158, accuracy=85.5%\n"
     ]
    }
   ],
   "source": [
    "print(\"Best beta=%f, accuracy=%.1f%%\" % (beta_vals[np.argmax(accuracy_val)], max(accuracy_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(beta_vals, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title(\"Test accuracy by regularization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "fc1_size = 4096\n",
    "fc2_size = 2048\n",
    "fc3_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    tf_beta = tf.placeholder(tf.float32)\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([image_size * image_size, fc1_size], stddev=np.sqrt(2.0 / (image_size * image_size))))\n",
    "    b1 = tf.Variable(tf.zeros([fc1_size]))\n",
    "    \n",
    "    W2 = tf.Variable(tf.truncated_normal([fc1_size, fc2_size], stddev=np.sqrt(2.0 / (fc1_size))))\n",
    "    b2 = tf.Variable(tf.zeros([fc2_size]))\n",
    "    \n",
    "    W3 = tf.Variable(tf.truncated_normal([fc2_size, fc3_size], stddev=np.sqrt(2.0 / (fc2_size))))\n",
    "    b3 = tf.Variable(tf.zeros([fc3_size]))\n",
    "    \n",
    "    W4 = tf.Variable(tf.truncated_normal([fc3_size, num_labels], stddev=np.sqrt(2.0 / (fc3_size))))\n",
    "    b4 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    y1 = tf.nn.relu(tf.matmul(tf_train_dataset, W1) + b1)\n",
    "    y2 = tf.nn.relu(tf.matmul(y1, W2) + b2)\n",
    "    y3 = tf.nn.relu(tf.matmul(y2, W3) + b3)\n",
    "    logits = tf.matmul(y3, W4) + b4\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=tf_train_labels))\n",
    "    \n",
    "    loss = loss + tf_beta * (tf.nn.l2_loss(W1) + tf.nn.l2_loss(b1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(b2) + \n",
    "                             tf.nn.l2_loss(W3) + tf.nn.l2_loss(b3) + tf.nn.l2_loss(W4) + tf.nn.l2_loss(b4))\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 1000, 0.7, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    train_predictions = tf.nn.softmax(logits)\n",
    "    \n",
    "    y1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, W1) + b1)\n",
    "    y2_valid = tf.nn.relu(tf.matmul(y1_valid, W2) + b2)\n",
    "    y3_valid = tf.nn.relu(tf.matmul(y2_valid, W3) + b3)\n",
    "    valid_logits = tf.matmul(y3_valid, W4) + b4\n",
    "    valid_predictions = tf.nn.softmax(valid_logits)\n",
    "    \n",
    "    y1_test = tf.nn.relu(tf.matmul(tf_test_dataset, W1) + b1)\n",
    "    y2_test = tf.nn.relu(tf.matmul(y1_test, W2) + b2)\n",
    "    y3_test = tf.nn.relu(tf.matmul(y2_test, W3) + b3)\n",
    "    test_logits = tf.matmul(y3_test, W4) + b4\n",
    "    test_predictions = tf.nn.softmax(test_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 9.354030\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 30.6%\n",
      "Final test accuracy: 92.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset+batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "        \n",
    "        feed_dict = {tf_train_dataset: batch_data, tf_train_labels: batch_labels, tf_beta: 0.001438}\n",
    "        \n",
    "        _, l, predictions = session.run([optimizer, loss, train_predictions], feed_dict=feed_dict)\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_predictions.eval(), valid_labels))\n",
    "    print(\"Final test accuracy: %.1f%%\" % accuracy(test_predictions.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "3_regularization.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
